{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-29T10:50:05.806934Z",
     "start_time": "2025-04-29T10:48:25.094240Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import io\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SimpleCNN:\n",
    "    def __init__(self, input_shape, num_filters=12, filter_size=6, num_classes=2):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_size = filter_size\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.filters = np.random.randn(num_filters, filter_size, filter_size, input_shape[2]) * 0.01\n",
    "        conv_output_size = input_shape[0] - filter_size + 1\n",
    "        self.flatten_size = conv_output_size * conv_output_size * num_filters\n",
    "        self.weights = np.random.randn(self.flatten_size, num_classes) * 0.01\n",
    "        self.bias = np.zeros((1, num_classes))\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "    def convolve(self, img, conv_filter):\n",
    "        h, w, c = img.shape\n",
    "        fh, fw, _ = conv_filter.shape\n",
    "        out = np.zeros((h - fh + 1, w - fw + 1))\n",
    "        for i in range(out.shape[0]):\n",
    "            for j in range(out.shape[1]):\n",
    "                region = img[i:i+fh, j:j+fw, :]\n",
    "                out[i, j] = np.sum(region * conv_filter)\n",
    "        return out\n",
    "\n",
    "    def forward(self, X):\n",
    "        batch_size = X.shape[0]\n",
    "        conv_outs = []\n",
    "        for img in X:\n",
    "            conv_maps = [self.relu(self.convolve(img, f)) for f in self.filters]\n",
    "            stacked = np.stack(conv_maps, axis=-1)\n",
    "            conv_outs.append(stacked)\n",
    "        conv_outs = np.array(conv_outs)\n",
    "        flat = conv_outs.reshape(batch_size, -1)\n",
    "        logits = flat @ self.weights + self.bias\n",
    "        return self.softmax(logits)\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.forward(X)\n",
    "        return [\"Normal\" if np.argmax(p) == 0 else \"Sepia\" for p in probs]\n",
    "\n",
    "    def one_hot(self, y):\n",
    "        return np.array([[1, 0] if label == \"Normal\" else [0, 1] for label in y])\n",
    "\n",
    "    def compute_loss(self, probs, labels_onehot):\n",
    "        return -np.mean(np.sum(labels_onehot * np.log(probs + 1e-8), axis=1))\n",
    "\n",
    "    def fit(self, X, y, epochs=100, lr=0.01):\n",
    "        y_encoded = self.one_hot(y)\n",
    "        for epoch in range(epochs):\n",
    "            probs = self.forward(X)\n",
    "            loss = self.compute_loss(probs, y_encoded)\n",
    "\n",
    "            # Forward again to get flattened conv output\n",
    "            conv_outs = []\n",
    "            for img in X:\n",
    "                conv_maps = [self.relu(self.convolve(img, f)) for f in self.filters]\n",
    "                stacked = np.stack(conv_maps, axis=-1)\n",
    "                conv_outs.append(stacked)\n",
    "            conv_outs = np.array(conv_outs)\n",
    "            flat = conv_outs.reshape(X.shape[0], -1)\n",
    "\n",
    "            d_logits = probs - y_encoded\n",
    "            dW = flat.T @ d_logits / X.shape[0]\n",
    "            db = np.sum(d_logits, axis=0, keepdims=True) / X.shape[0]\n",
    "\n",
    "            self.weights -= lr * dW\n",
    "            self.bias -= lr * db\n",
    "\n",
    "            if epoch % 10 == 0 or epoch == epochs - 1:\n",
    "                print(f\"Epoch {epoch}: Loss = {loss:.4f}\")\n",
    "\n",
    "def loadData():\n",
    "    currentPath = os.path.join(os.getcwd(), \"Photos\")\n",
    "    inputs, outputs = [], []\n",
    "    for file in os.listdir(currentPath):\n",
    "        label = \"Normal\" if \"person\" in file else \"Sepia\"\n",
    "        file_path = os.path.join(currentPath, file)\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            img = Image.open(io.BytesIO(f.read())).convert(\"RGB\")\n",
    "            inputs.append(img)\n",
    "            outputs.append(label)\n",
    "    return inputs, outputs\n",
    "\n",
    "def resize_images(images, target_size=(32, 32)):\n",
    "    return np.array([np.array(img.resize(target_size)) / 255.0 for img in images])\n",
    "\n",
    "def splitData(inputs, outputs):\n",
    "    np.random.seed(5)\n",
    "    indexes = np.arange(len(inputs))\n",
    "    np.random.shuffle(indexes)\n",
    "    split = int(0.8 * len(inputs))\n",
    "    train_idx, test_idx = indexes[:split], indexes[split:]\n",
    "    return [inputs[i] for i in train_idx], [outputs[i] for i in train_idx], [inputs[i] for i in test_idx], [outputs[i] for i in test_idx]\n",
    "\n",
    "# === Main logic ===\n",
    "inputs, outputs = loadData()\n",
    "inputs_resized = resize_images(inputs, (8, 8))\n",
    "trainX, trainY, testX, testY = splitData(inputs_resized, outputs)\n",
    "\n",
    "X_train = np.array(trainX)\n",
    "X_test = np.array(testX)\n",
    "\n",
    "model = SimpleCNN(input_shape=(8, 8, 3))\n",
    "model.fit(X_train, trainY, epochs=3000, lr=0.001)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(\"Predictions:\", predictions)\n",
    "print(\"Actual:     \", testY)\n",
    "print(\"Accuracy:   \", accuracy_score(testY, predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(testY, predictions))\n",
    "\n",
    "cm = confusion_matrix(testY, predictions, labels=[\"Normal\", \"Sepia\"])\n",
    "ConfusionMatrixDisplay(cm, display_labels=[\"Normal\", \"Sepia\"]).plot(cmap='Blues')\n",
    "plt.show()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 0.6928\n",
      "Epoch 10: Loss = 0.6928\n",
      "Epoch 20: Loss = 0.6927\n",
      "Epoch 30: Loss = 0.6927\n",
      "Epoch 40: Loss = 0.6927\n",
      "Epoch 50: Loss = 0.6926\n",
      "Epoch 60: Loss = 0.6926\n",
      "Epoch 70: Loss = 0.6926\n",
      "Epoch 80: Loss = 0.6926\n",
      "Epoch 90: Loss = 0.6925\n",
      "Epoch 100: Loss = 0.6925\n",
      "Epoch 110: Loss = 0.6925\n",
      "Epoch 120: Loss = 0.6925\n",
      "Epoch 130: Loss = 0.6925\n",
      "Epoch 140: Loss = 0.6924\n",
      "Epoch 150: Loss = 0.6924\n",
      "Epoch 160: Loss = 0.6924\n",
      "Epoch 170: Loss = 0.6924\n",
      "Epoch 180: Loss = 0.6923\n",
      "Epoch 190: Loss = 0.6923\n",
      "Epoch 200: Loss = 0.6923\n",
      "Epoch 210: Loss = 0.6923\n",
      "Epoch 220: Loss = 0.6922\n",
      "Epoch 230: Loss = 0.6922\n",
      "Epoch 240: Loss = 0.6922\n",
      "Epoch 250: Loss = 0.6922\n",
      "Epoch 260: Loss = 0.6922\n",
      "Epoch 270: Loss = 0.6921\n",
      "Epoch 280: Loss = 0.6921\n",
      "Epoch 290: Loss = 0.6921\n",
      "Epoch 300: Loss = 0.6921\n",
      "Epoch 310: Loss = 0.6920\n",
      "Epoch 320: Loss = 0.6920\n",
      "Epoch 330: Loss = 0.6920\n",
      "Epoch 340: Loss = 0.6920\n",
      "Epoch 350: Loss = 0.6920\n",
      "Epoch 360: Loss = 0.6919\n",
      "Epoch 370: Loss = 0.6919\n",
      "Epoch 380: Loss = 0.6919\n",
      "Epoch 390: Loss = 0.6919\n",
      "Epoch 400: Loss = 0.6919\n",
      "Epoch 410: Loss = 0.6918\n",
      "Epoch 420: Loss = 0.6918\n",
      "Epoch 430: Loss = 0.6918\n",
      "Epoch 440: Loss = 0.6918\n",
      "Epoch 450: Loss = 0.6918\n",
      "Epoch 460: Loss = 0.6917\n",
      "Epoch 470: Loss = 0.6917\n",
      "Epoch 480: Loss = 0.6917\n",
      "Epoch 490: Loss = 0.6917\n",
      "Epoch 500: Loss = 0.6917\n",
      "Epoch 510: Loss = 0.6916\n",
      "Epoch 520: Loss = 0.6916\n",
      "Epoch 530: Loss = 0.6916\n",
      "Epoch 540: Loss = 0.6916\n",
      "Epoch 550: Loss = 0.6916\n",
      "Epoch 560: Loss = 0.6916\n",
      "Epoch 570: Loss = 0.6915\n",
      "Epoch 580: Loss = 0.6915\n",
      "Epoch 590: Loss = 0.6915\n",
      "Epoch 600: Loss = 0.6915\n",
      "Epoch 610: Loss = 0.6915\n",
      "Epoch 620: Loss = 0.6914\n",
      "Epoch 630: Loss = 0.6914\n",
      "Epoch 640: Loss = 0.6914\n",
      "Epoch 650: Loss = 0.6914\n",
      "Epoch 660: Loss = 0.6914\n",
      "Epoch 670: Loss = 0.6914\n",
      "Epoch 680: Loss = 0.6913\n",
      "Epoch 690: Loss = 0.6913\n",
      "Epoch 700: Loss = 0.6913\n",
      "Epoch 710: Loss = 0.6913\n",
      "Epoch 720: Loss = 0.6913\n",
      "Epoch 730: Loss = 0.6913\n",
      "Epoch 740: Loss = 0.6912\n",
      "Epoch 750: Loss = 0.6912\n",
      "Epoch 760: Loss = 0.6912\n",
      "Epoch 770: Loss = 0.6912\n",
      "Epoch 780: Loss = 0.6912\n",
      "Epoch 790: Loss = 0.6912\n",
      "Epoch 800: Loss = 0.6911\n",
      "Epoch 810: Loss = 0.6911\n",
      "Epoch 820: Loss = 0.6911\n",
      "Epoch 830: Loss = 0.6911\n",
      "Epoch 840: Loss = 0.6911\n",
      "Epoch 850: Loss = 0.6911\n",
      "Epoch 860: Loss = 0.6910\n",
      "Epoch 870: Loss = 0.6910\n",
      "Epoch 880: Loss = 0.6910\n",
      "Epoch 890: Loss = 0.6910\n",
      "Epoch 900: Loss = 0.6910\n",
      "Epoch 910: Loss = 0.6910\n",
      "Epoch 920: Loss = 0.6909\n",
      "Epoch 930: Loss = 0.6909\n",
      "Epoch 940: Loss = 0.6909\n",
      "Epoch 950: Loss = 0.6909\n",
      "Epoch 960: Loss = 0.6909\n",
      "Epoch 970: Loss = 0.6909\n",
      "Epoch 980: Loss = 0.6909\n",
      "Epoch 990: Loss = 0.6908\n",
      "Epoch 1000: Loss = 0.6908\n",
      "Epoch 1010: Loss = 0.6908\n",
      "Epoch 1020: Loss = 0.6908\n",
      "Epoch 1030: Loss = 0.6908\n",
      "Epoch 1040: Loss = 0.6908\n",
      "Epoch 1050: Loss = 0.6908\n",
      "Epoch 1060: Loss = 0.6907\n",
      "Epoch 1070: Loss = 0.6907\n",
      "Epoch 1080: Loss = 0.6907\n",
      "Epoch 1090: Loss = 0.6907\n",
      "Epoch 1100: Loss = 0.6907\n",
      "Epoch 1110: Loss = 0.6907\n",
      "Epoch 1120: Loss = 0.6906\n",
      "Epoch 1130: Loss = 0.6906\n",
      "Epoch 1140: Loss = 0.6906\n",
      "Epoch 1150: Loss = 0.6906\n",
      "Epoch 1160: Loss = 0.6906\n",
      "Epoch 1170: Loss = 0.6906\n",
      "Epoch 1180: Loss = 0.6906\n",
      "Epoch 1190: Loss = 0.6905\n",
      "Epoch 1200: Loss = 0.6905\n",
      "Epoch 1210: Loss = 0.6905\n",
      "Epoch 1220: Loss = 0.6905\n",
      "Epoch 1230: Loss = 0.6905\n",
      "Epoch 1240: Loss = 0.6905\n",
      "Epoch 1250: Loss = 0.6905\n",
      "Epoch 1260: Loss = 0.6905\n",
      "Epoch 1270: Loss = 0.6904\n",
      "Epoch 1280: Loss = 0.6904\n",
      "Epoch 1290: Loss = 0.6904\n",
      "Epoch 1300: Loss = 0.6904\n",
      "Epoch 1310: Loss = 0.6904\n",
      "Epoch 1320: Loss = 0.6904\n",
      "Epoch 1330: Loss = 0.6904\n",
      "Epoch 1340: Loss = 0.6903\n",
      "Epoch 1350: Loss = 0.6903\n",
      "Epoch 1360: Loss = 0.6903\n",
      "Epoch 1370: Loss = 0.6903\n",
      "Epoch 1380: Loss = 0.6903\n",
      "Epoch 1390: Loss = 0.6903\n",
      "Epoch 1400: Loss = 0.6903\n",
      "Epoch 1410: Loss = 0.6903\n",
      "Epoch 1420: Loss = 0.6902\n",
      "Epoch 1430: Loss = 0.6902\n",
      "Epoch 1440: Loss = 0.6902\n",
      "Epoch 1450: Loss = 0.6902\n",
      "Epoch 1460: Loss = 0.6902\n",
      "Epoch 1470: Loss = 0.6902\n",
      "Epoch 1480: Loss = 0.6902\n",
      "Epoch 1490: Loss = 0.6901\n",
      "Epoch 1500: Loss = 0.6901\n",
      "Epoch 1510: Loss = 0.6901\n",
      "Epoch 1520: Loss = 0.6901\n",
      "Epoch 1530: Loss = 0.6901\n",
      "Epoch 1540: Loss = 0.6901\n",
      "Epoch 1550: Loss = 0.6901\n",
      "Epoch 1560: Loss = 0.6901\n",
      "Epoch 1570: Loss = 0.6900\n",
      "Epoch 1580: Loss = 0.6900\n",
      "Epoch 1590: Loss = 0.6900\n",
      "Epoch 1600: Loss = 0.6900\n",
      "Epoch 1610: Loss = 0.6900\n",
      "Epoch 1620: Loss = 0.6900\n",
      "Epoch 1630: Loss = 0.6900\n",
      "Epoch 1640: Loss = 0.6900\n",
      "Epoch 1650: Loss = 0.6899\n",
      "Epoch 1660: Loss = 0.6899\n",
      "Epoch 1670: Loss = 0.6899\n",
      "Epoch 1680: Loss = 0.6899\n",
      "Epoch 1690: Loss = 0.6899\n",
      "Epoch 1700: Loss = 0.6899\n",
      "Epoch 1710: Loss = 0.6899\n",
      "Epoch 1720: Loss = 0.6899\n",
      "Epoch 1730: Loss = 0.6898\n",
      "Epoch 1740: Loss = 0.6898\n",
      "Epoch 1750: Loss = 0.6898\n",
      "Epoch 1760: Loss = 0.6898\n",
      "Epoch 1770: Loss = 0.6898\n",
      "Epoch 1780: Loss = 0.6898\n",
      "Epoch 1790: Loss = 0.6898\n",
      "Epoch 1800: Loss = 0.6898\n",
      "Epoch 1810: Loss = 0.6898\n",
      "Epoch 1820: Loss = 0.6897\n",
      "Epoch 1830: Loss = 0.6897\n",
      "Epoch 1840: Loss = 0.6897\n",
      "Epoch 1850: Loss = 0.6897\n",
      "Epoch 1860: Loss = 0.6897\n",
      "Epoch 1870: Loss = 0.6897\n",
      "Epoch 1880: Loss = 0.6897\n",
      "Epoch 1890: Loss = 0.6897\n",
      "Epoch 1900: Loss = 0.6896\n",
      "Epoch 1910: Loss = 0.6896\n",
      "Epoch 1920: Loss = 0.6896\n",
      "Epoch 1930: Loss = 0.6896\n",
      "Epoch 1940: Loss = 0.6896\n",
      "Epoch 1950: Loss = 0.6896\n",
      "Epoch 1960: Loss = 0.6896\n",
      "Epoch 1970: Loss = 0.6896\n",
      "Epoch 1980: Loss = 0.6895\n",
      "Epoch 1990: Loss = 0.6895\n",
      "Epoch 2000: Loss = 0.6895\n",
      "Epoch 2010: Loss = 0.6895\n",
      "Epoch 2020: Loss = 0.6895\n",
      "Epoch 2030: Loss = 0.6895\n",
      "Epoch 2040: Loss = 0.6895\n",
      "Epoch 2050: Loss = 0.6895\n",
      "Epoch 2060: Loss = 0.6895\n",
      "Epoch 2070: Loss = 0.6894\n",
      "Epoch 2080: Loss = 0.6894\n",
      "Epoch 2090: Loss = 0.6894\n",
      "Epoch 2100: Loss = 0.6894\n",
      "Epoch 2110: Loss = 0.6894\n",
      "Epoch 2120: Loss = 0.6894\n",
      "Epoch 2130: Loss = 0.6894\n",
      "Epoch 2140: Loss = 0.6894\n",
      "Epoch 2150: Loss = 0.6894\n",
      "Epoch 2160: Loss = 0.6893\n",
      "Epoch 2170: Loss = 0.6893\n",
      "Epoch 2180: Loss = 0.6893\n",
      "Epoch 2190: Loss = 0.6893\n",
      "Epoch 2200: Loss = 0.6893\n",
      "Epoch 2210: Loss = 0.6893\n",
      "Epoch 2220: Loss = 0.6893\n",
      "Epoch 2230: Loss = 0.6893\n",
      "Epoch 2240: Loss = 0.6893\n",
      "Epoch 2250: Loss = 0.6892\n",
      "Epoch 2260: Loss = 0.6892\n",
      "Epoch 2270: Loss = 0.6892\n",
      "Epoch 2280: Loss = 0.6892\n",
      "Epoch 2290: Loss = 0.6892\n",
      "Epoch 2300: Loss = 0.6892\n",
      "Epoch 2310: Loss = 0.6892\n",
      "Epoch 2320: Loss = 0.6892\n",
      "Epoch 2330: Loss = 0.6892\n",
      "Epoch 2340: Loss = 0.6891\n",
      "Epoch 2350: Loss = 0.6891\n",
      "Epoch 2360: Loss = 0.6891\n",
      "Epoch 2370: Loss = 0.6891\n",
      "Epoch 2380: Loss = 0.6891\n",
      "Epoch 2390: Loss = 0.6891\n",
      "Epoch 2400: Loss = 0.6891\n",
      "Epoch 2410: Loss = 0.6891\n",
      "Epoch 2420: Loss = 0.6891\n",
      "Epoch 2430: Loss = 0.6890\n",
      "Epoch 2440: Loss = 0.6890\n",
      "Epoch 2450: Loss = 0.6890\n",
      "Epoch 2460: Loss = 0.6890\n",
      "Epoch 2470: Loss = 0.6890\n",
      "Epoch 2480: Loss = 0.6890\n",
      "Epoch 2490: Loss = 0.6890\n",
      "Epoch 2500: Loss = 0.6890\n",
      "Epoch 2510: Loss = 0.6890\n",
      "Epoch 2520: Loss = 0.6889\n",
      "Epoch 2530: Loss = 0.6889\n",
      "Epoch 2540: Loss = 0.6889\n",
      "Epoch 2550: Loss = 0.6889\n",
      "Epoch 2560: Loss = 0.6889\n",
      "Epoch 2570: Loss = 0.6889\n",
      "Epoch 2580: Loss = 0.6889\n",
      "Epoch 2590: Loss = 0.6889\n",
      "Epoch 2600: Loss = 0.6889\n",
      "Epoch 2610: Loss = 0.6888\n",
      "Epoch 2620: Loss = 0.6888\n",
      "Epoch 2630: Loss = 0.6888\n",
      "Epoch 2640: Loss = 0.6888\n",
      "Epoch 2650: Loss = 0.6888\n",
      "Epoch 2660: Loss = 0.6888\n",
      "Epoch 2670: Loss = 0.6888\n",
      "Epoch 2680: Loss = 0.6888\n",
      "Epoch 2690: Loss = 0.6888\n",
      "Epoch 2700: Loss = 0.6888\n",
      "Epoch 2710: Loss = 0.6887\n",
      "Epoch 2720: Loss = 0.6887\n",
      "Epoch 2730: Loss = 0.6887\n",
      "Epoch 2740: Loss = 0.6887\n",
      "Epoch 2750: Loss = 0.6887\n",
      "Epoch 2760: Loss = 0.6887\n",
      "Epoch 2770: Loss = 0.6887\n",
      "Epoch 2780: Loss = 0.6887\n",
      "Epoch 2790: Loss = 0.6887\n",
      "Epoch 2800: Loss = 0.6886\n",
      "Epoch 2810: Loss = 0.6886\n",
      "Epoch 2820: Loss = 0.6886\n",
      "Epoch 2830: Loss = 0.6886\n",
      "Epoch 2840: Loss = 0.6886\n",
      "Epoch 2850: Loss = 0.6886\n",
      "Epoch 2860: Loss = 0.6886\n",
      "Epoch 2870: Loss = 0.6886\n",
      "Epoch 2880: Loss = 0.6886\n",
      "Epoch 2890: Loss = 0.6886\n",
      "Epoch 2900: Loss = 0.6885\n",
      "Epoch 2910: Loss = 0.6885\n",
      "Epoch 2920: Loss = 0.6885\n",
      "Epoch 2930: Loss = 0.6885\n",
      "Epoch 2940: Loss = 0.6885\n",
      "Epoch 2950: Loss = 0.6885\n",
      "Epoch 2960: Loss = 0.6885\n",
      "Epoch 2970: Loss = 0.6885\n",
      "Epoch 2980: Loss = 0.6885\n",
      "Epoch 2990: Loss = 0.6884\n",
      "Epoch 2999: Loss = 0.6884\n",
      "Predictions: ['Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal']\n",
      "Actual:      ['Sepia', 'Sepia', 'Sepia', 'Normal', 'Normal', 'Normal', 'Sepia', 'Sepia', 'Normal', 'Sepia']\n",
      "Accuracy:    0.4\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.40      1.00      0.57         4\n",
      "       Sepia       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.40        10\n",
      "   macro avg       0.20      0.50      0.29        10\n",
      "weighted avg       0.16      0.40      0.23        10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berin\\PycharmProjects\\Lab7\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\berin\\PycharmProjects\\Lab7\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\berin\\PycharmProjects\\Lab7\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T10:46:43.580954Z",
     "start_time": "2025-04-29T10:46:43.578457Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "af9dc4a79ea9cd7f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
